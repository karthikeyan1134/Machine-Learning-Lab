{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj7UafMP_FTV",
        "outputId": "2f86defc-592b-4541-e0c1-f9c178199e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Constructed Decision Tree ---\n",
            "{0: {'D1': 'No', 'D10': 'Yes', 'D11': 'Yes', 'D12': 'Yes', 'D13': 'Yes', 'D14': 'No', 'D2': 'No', 'D3': 'Yes', 'D4': 'Yes', 'D5': 'Yes', 'D6': 'No', 'D7': 'Yes', 'D8': 'No', 'D9': 'Yes'}}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Function to calculate entropy\n",
        "def calculate_entropy(y):\n",
        "    values, counts = np.unique(y, return_counts=True)\n",
        "    probabilities = counts / len(y)\n",
        "    return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "# Function to calculate information gain for a specific feature\n",
        "def compute_info_gain(X, y, feature_index):\n",
        "    unique_values = np.unique(X[:, feature_index])\n",
        "    weighted_entropy = 0\n",
        "    for value in unique_values:\n",
        "        subset_y = y[X[:, feature_index] == value]\n",
        "        weighted_entropy += (len(subset_y) / len(y)) * calculate_entropy(subset_y)\n",
        "    return calculate_entropy(y) - weighted_entropy\n",
        "\n",
        "# Function to find the best feature to split on\n",
        "def find_best_feature(X, y):\n",
        "    information_gains = [compute_info_gain(X, y, i) for i in range(X.shape[1])]\n",
        "    return np.argmax(information_gains)\n",
        "\n",
        "# Recursive function to build the decision tree\n",
        "def build_decision_tree(X, y):\n",
        "    if len(np.unique(y)) == 1:\n",
        "        return np.unique(y)[0]\n",
        "    if X.shape[1] == 0:\n",
        "        return np.bincount(y).argmax()\n",
        "\n",
        "    best_feature_index = find_best_feature(X, y)\n",
        "    decision_tree_structure = {best_feature_index: {}}\n",
        "\n",
        "    for value in np.unique(X[:, best_feature_index]):\n",
        "        sub_X = X[X[:, best_feature_index] == value]\n",
        "        sub_y = y[X[:, best_feature_index] == value]\n",
        "        decision_tree_structure[best_feature_index][value] = build_decision_tree(np.delete(sub_X, best_feature_index, axis=1), sub_y)\n",
        "\n",
        "    return decision_tree_structure\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/sample_data/play_tennis.csv')\n",
        "features = data.iloc[:, :-1].values\n",
        "target = data.iloc[:, -1].values\n",
        "\n",
        "# Build the decision tree\n",
        "constructed_tree = build_decision_tree(features, target)\n",
        "\n",
        "# Print the constructed decision tree\n",
        "print(\"\\n--- Constructed Decision Tree ---\")\n",
        "print(constructed_tree)\n"
      ]
    }
  ]
}